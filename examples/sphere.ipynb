{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exampe: sphere\n",
    "\n",
    "This notebook shows how to use `ffsas` to invert for the radius distribution of a `sphere` model. It uses the [SASView/SASModels](http://www.sasview.org/docs/user/models/sphere.html) unit system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avoid omp error on Mac\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "# plotting setup\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 22})\n",
    "matplotlib.rcParams.update({'legend.fontsize': 20})\n",
    "matplotlib.rcParams.update({'axes.titlesize': 22})\n",
    "matplotlib.rcParams.update({'lines.linewidth': 2})\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"text.latex.preamble\":  r'\\usepackage{bm,upgreek}',\n",
    "    \"font.family\": \"sans-serif\",\n",
    "    \"font.serif\": [\"Times\"]})\n",
    "\n",
    "# create output dir\n",
    "from pathlib import Path\n",
    "paper_fig_dir = Path('./output/paper_fig')\n",
    "Path(paper_fig_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment this line to install ffsas\n",
    "# !pip install ffsas\n",
    "\n",
    "# ffsas\n",
    "import torch\n",
    "from ffsas.models import Sphere\n",
    "from ffsas.system import SASGreensSystem\n",
    "\n",
    "# math tools\n",
    "from scipy import interpolate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ground truth\n",
    "\n",
    "To do inversion, we need some intensity data as input. Here we create the data by modelling, using a noisy radius distribution, or the ground truth.  \n",
    "\n",
    "### Ground truth of radius distribution\n",
    "\n",
    "The following function creates a \"crazy\" distribution by adding up Gaussians and random noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crazy_distribution(x, gaussians, noise_level, fade_start, fade_end, seed=0):\n",
    "    # create\n",
    "    w_true = torch.zeros(x.shape)\n",
    "    \n",
    "    # add Gaussians\n",
    "    for factor, mean, stddev in gaussians:\n",
    "        w_true += factor * torch.exp(-((x - mean) / stddev) ** 2)\n",
    "    \n",
    "    # add noise\n",
    "    torch.random.manual_seed(seed)\n",
    "    w_true += noise_level * torch.rand(x.shape) * torch.rand(x.shape)\n",
    "    \n",
    "    # fade both ends to make it look nicer\n",
    "    w_true[0:fade_start] = 0.\n",
    "    w_true[fade_start:fade_end] *= torch.linspace(0, 1, fade_end - fade_start)\n",
    "    w_true[-fade_start:] = 0.\n",
    "    w_true[-fade_end:-fade_start] *= torch.linspace(1, 0, fade_end - fade_start)\n",
    "    \n",
    "    # normalize to 1\n",
    "    w_true /= torch.sum(w_true)\n",
    "    return w_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a radius distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# radius vector\n",
    "r = torch.linspace(500., 1000., 300)\n",
    "\n",
    "# Make a crazy radius distribution with Gaussian and random\n",
    "w_true = crazy_distribution(r, [(4, 580, 10), (6, 630, 20), (10, 700, 20), \n",
    "                                (12, 750, 20), (8, 850, 15), (5, 930, 15)],\n",
    "                            noise_level=10, fade_start=10, fade_end=40)\n",
    "\n",
    "# upsample weights to a higher resolution for later use\n",
    "high_reso = 400\n",
    "r_high = torch.linspace(r[0], r[-1], high_reso)\n",
    "w_true_high = torch.tensor(interpolate.interp1d(r, w_true)(r_high))\n",
    "w_true_high /= torch.sum(w_true_high)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground truth of intensity\n",
    "\n",
    "Now, based on the above radius distribution, we compute the ground truth of intensity. \n",
    "\n",
    "Note that the parameter `scale` in [SASView/SASModels](http://www.sasview.org/docs/user/models/sphere.html) is not the $\\xi$ in `ffsas`. For the particular unit system of [SASView/SASModels](http://www.sasview.org/docs/user/models/sphere.html), the relation between `scale` and $\\xi$ is\n",
    "\n",
    "$$\\xi=10^{-4}\\times\\dfrac{\\mathrm{scale}}{V_\\text{ave}},$$\n",
    "\n",
    "where $10^{-4}$ comes from the unit system and $V_\\text{ave}$ is the average volume. The `background` in [SASView/SASModels](http://www.sasview.org/docs/user/models/sphere.html) has the same definition as $b$ in `ffsas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground truth of scale and background\n",
    "scale_true = 2.5\n",
    "b_true = .14\n",
    "\n",
    "# q vector\n",
    "q = torch.linspace(.001, 1, 2000)\n",
    "\n",
    "# (SLD - SLD_solvent) ^ 2\n",
    "drho = 25.\n",
    "\n",
    "# comupute the Green's function and volume\n",
    "G = Sphere.compute_G_mini_batch([q], {'r': r}, {'drho': drho})\n",
    "\n",
    "# compute the ground truth of xi\n",
    "V = Sphere.compute_V({'r': r})\n",
    "V_ave = torch.dot(V, w_true)\n",
    "xi_true = 1e-4 * scale_true / V_ave\n",
    "\n",
    "# define the G-based SAS system\n",
    "g_sys = SASGreensSystem(G, Sphere.get_par_keys_G(), log_screen=True)\n",
    "\n",
    "# finally compute the ground truth of intensity\n",
    "I_true = g_sys.compute_intensity({'r': w_true}, xi_true, b_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the ground truths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=200, ncols=2, figsize=(15, 4))\n",
    "ax[0].plot(r, w_true)\n",
    "ax[0].set_xlabel(r'Radius, $r$ ($\\AA$)')\n",
    "ax[0].set_ylabel(r'Weights, $w$')\n",
    "ax[1].plot(q, I_true)\n",
    "ax[1].set_xscale('log')\n",
    "ax[1].set_yscale('log')\n",
    "ax[1].set_xlabel(r'Scattering vector, $q$ ($\\AA^{-1}$)')\n",
    "ax[1].set_ylabel(r'Intensity, $I$ ($\\mathrm{cm}^{-1}$)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Inversion\n",
    "\n",
    "Now we solve the inverse problem at different radius resolutions. It is expected that we \"exactly\" reproduce the ground truth with the resolution it was created, or 300 (`r = torch.linspace(500., 1000., 300)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# solve at four resolutions\n",
    "resolutions = [100, 200, 300, 400]\n",
    "results = []\n",
    "\n",
    "# to avoid some drifting at low resolution 50, we do not use 1.0\n",
    "nu_sigma = 0.8  \n",
    "\n",
    "# loop over resolutions\n",
    "for reso in resolutions:\n",
    "    # resampled r vector at given resolution\n",
    "    r_reso = torch.linspace(r[0], r[-1], reso)\n",
    "    \n",
    "    # recompute G\n",
    "    G_reso = Sphere.compute_G_mini_batch([q], {'r': r_reso}, {'drho': drho}, log_screen=False)\n",
    "    \n",
    "    # define the system\n",
    "    g_sys_reso = SASGreensSystem(G_reso, par_keys=Sphere.get_par_keys_G())\n",
    "    \n",
    "    # solve the inverse problem using \"true\" intensity\n",
    "    # NOTE: we do not have sigma or data uncertainty, so we use mu as sigma\n",
    "    result_dict = g_sys_reso.solve_inverse(I_true, I_true, nu_sigma=nu_sigma,\n",
    "                                           auto_scaling=True, maxiter=1000, verbose=2)\n",
    "    \n",
    "    # get weights from result dict\n",
    "    w_reso = result_dict['w_dict']['r']\n",
    "    sens_w_reso = result_dict['sens_w_dict']['r']\n",
    "    \n",
    "    # compute scale \n",
    "    scale = result_dict['xi'] * V_ave / 1e-4\n",
    "\n",
    "    # upsample w to high resolution so we can plot them together\n",
    "    w_high = torch.tensor(interpolate.interp1d(r_reso, w_reso)(r_high))\n",
    "    w_high /= torch.sum(w_high)\n",
    "    sens_w_high = torch.tensor(interpolate.interp1d(r_reso, sens_w_reso)(r_high))\n",
    "    sens_w_high /= torch.sum(sens_w_high)\n",
    "    results.append((reso, w_reso, w_high, sens_w_high, scale, result_dict['xi'], result_dict['b'], \n",
    "                    result_dict['I'], result_dict['wct']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, plot the results at the different resolutions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# scaling factor to plot 1/sensitivity as uncertainty \n",
    "scaling_factor_sensitivity = 3e-6\n",
    "\n",
    "# set up figure\n",
    "fig, ax = plt.subplots(nrows=len(results), ncols=2, dpi=200, figsize=(18, len(results) * 3))\n",
    "plt.subplots_adjust(hspace=.3)\n",
    "if len(results) == 1:\n",
    "    ax = [ax]\n",
    "\n",
    "for i, (reso, w_reso, w_high, sens_w_high, scale, xi, b, I, wct) in enumerate(results):\n",
    "    #######################\n",
    "    # radius distribution #\n",
    "    #######################\n",
    "    # truth\n",
    "    ax[i][0].scatter(r_high, w_true_high * 100, lw=0, c=colors[0], s=30, \n",
    "                     label=r'$w_\\mathrm{true}(r)$')\n",
    "    # inverted\n",
    "    ax[i][0].plot(r_high, w_high * 100, c=colors[1], label=r'$w_\\mathrm{fit}(r)$')\n",
    "    dw_norm = torch.norm(w_true_high - w_high) / len(w_high)\n",
    "    # 1/sensitivity\n",
    "    sens_scaled = scaling_factor_sensitivity / sens_w_high\n",
    "    ax[i][0].fill_between(r_high, (w_high - abs(sens_scaled)) * 100, (w_high + abs(sens_scaled)) * 100, \n",
    "                          alpha=.3, color='gray', zorder=-100, label=r'${S}^{-1}(r)$')\n",
    "    ax[i][0].set_title(r'$w_\\mathrm{fit}(r)$ res.=%d: $|\\mathbf{w}_\\mathrm{fit}-\\mathbf{w}_\\mathrm{true}|$=%.2E' % (reso, dw_norm))\n",
    "    ax[i][0].set_ylim(-0.1, 1.2)\n",
    "    ax[i][0].set_ylabel(r'$w$ (\\%)')\n",
    "    ax[0][0].set_ylabel(r'Weight, $w$ (\\%)')\n",
    "    \n",
    "    if i != len(results) - 1:\n",
    "        ax[i][0].set_xticklabels([])\n",
    "    else:\n",
    "        ax[i][0].set_xlabel(r'Radius, $r$ (\\AA)')\n",
    "    ax[i][0].set_xlim(500,1000)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #####################\n",
    "    # intensity fitting #\n",
    "    #####################\n",
    "    eps_norm = torch.norm((I_true - I) / I_true ** nu_sigma) / len(I_true)\n",
    "    # truth\n",
    "    ax[i][1].scatter(q, I_true, lw=0, c=colors[2], s=30, label=r'$I_\\mathrm{true}(q)$')\n",
    "    # fitted\n",
    "    ax[i][1].plot(q, I, c=colors[3], label=r'$I_\\mathrm{fit}(q)$')\n",
    "    ax[i][1].set_title(r'$w_\\mathrm{fit}(r)$ res.=%d: $||\\bm{\\upepsilon}||$=%.2E, wt=%.1f sec' % (reso, eps_norm, wct))\n",
    "    ax[i][1].set_xscale('log')\n",
    "    ax[i][1].set_yscale('log')\n",
    "    ax[i][1].set_ylabel(r'$I$ ($\\mathrm{cm}^{-1}$)')\n",
    "    ax[0][1].set_ylabel(r'Intensity, $I$ ($\\mathrm{cm}^{-1}$)')\n",
    "    if i != len(results) - 1:\n",
    "        ax[i][1].set_xticklabels([])\n",
    "    else:\n",
    "        ax[i][1].set_xlabel(r'Scattering vector, $q$ (\\AA$^{-1}$)')\n",
    "    ax[i][1].set_yticks([1, 1e4, 1e8])\n",
    "    ax[i][1].set_xlim(1e-3, 1)\n",
    "    \n",
    "    # add some text\n",
    "    if reso == 300:\n",
    "        ax[i][0].text(.97, .92, 'Exact', transform=ax[i][0].transAxes, \n",
    "                     ha='right', va='top', fontsize=22, color='k')\n",
    "        ax[i][1].text(.97, .92, 'Exact', transform=ax[i][1].transAxes, \n",
    "                     ha='right', va='top', fontsize=22, color='k')\n",
    "\n",
    "# legend\n",
    "order = [1, 0, 2]\n",
    "handles, labels = ax[0][0].get_legend_handles_labels()\n",
    "ax[0][0].legend([handles[idx] for idx in order], [labels[idx] for idx in order], \n",
    "                handlelength=1, loc=[.16,.7], ncol=3, columnspacing=1.5)\n",
    "ax[0][0].set_ylim(-0.1, 1.2)\n",
    "handles, labels = ax[0][1].get_legend_handles_labels()\n",
    "order = [1, 0]\n",
    "ax[0][1].legend([handles[idx] for idx in order], [labels[idx] for idx in order], handlelength=1)\n",
    "\n",
    "# save figure for paper \n",
    "plt.savefig(paper_fig_dir / 'sphere.pdf', bbox_inches='tight', facecolor='w', pad_inches=.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
