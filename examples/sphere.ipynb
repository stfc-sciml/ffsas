{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b8965ae",
   "metadata": {},
   "source": [
    "# Exampe: sphere\n",
    "\n",
    "This notebook shows how to use `ffsas` to invert for the radius distribution of a `sphere` model. It uses the [SASView/SASModels](http://www.sasview.org/docs/user/models/sphere.html) unit system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dbd827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avoid omp error on Mac\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "# plotting setup\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 12})\n",
    "matplotlib.rcParams.update({'legend.fontsize': 11})\n",
    "matplotlib.rcParams.update({'axes.titlesize': 12})\n",
    "matplotlib.rcParams.update({'lines.linewidth': 2})\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "# create output dir\n",
    "from pathlib import Path\n",
    "output_dir = Path('./output/sphere')\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c991e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment this line to install ffsas\n",
    "# !pip install ffsas\n",
    "\n",
    "# ffsas\n",
    "import torch\n",
    "from ffsas.models import Sphere\n",
    "from ffsas.system import SASGreensSystem\n",
    "\n",
    "# math tools\n",
    "from scipy import interpolate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defb4dac",
   "metadata": {},
   "source": [
    "# Ground truth\n",
    "\n",
    "To do inversion, we need some intensity data as input. Here we create the data by modelling, using a noisy radius distribution, or the ground truth.  \n",
    "\n",
    "### Ground truth of radius distribution\n",
    "\n",
    "The following function creates a \"crazy\" distribution by adding up Gaussians and random noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6386f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crazy_distribution(x, gaussians, noise_level, fade_start, fade_end, seed=0):\n",
    "    # create\n",
    "    w_true = torch.zeros(x.shape)\n",
    "    \n",
    "    # add Gaussians\n",
    "    for factor, mean, stddev in gaussians:\n",
    "        w_true += factor * torch.exp(-((x - mean) / stddev) ** 2)\n",
    "    \n",
    "    # add noise\n",
    "    torch.random.manual_seed(seed)\n",
    "    w_true += noise_level * torch.rand(x.shape) * torch.rand(x.shape)\n",
    "    \n",
    "    # fade both ends to make it look nicer\n",
    "    w_true[0:fade_start] = 0.\n",
    "    w_true[fade_start:fade_end] *= torch.linspace(0, 1, fade_end - fade_start)\n",
    "    w_true[-fade_start:] = 0.\n",
    "    w_true[-fade_end:-fade_start] *= torch.linspace(1, 0, fade_end - fade_start)\n",
    "    \n",
    "    # normalize to 1\n",
    "    w_true /= torch.sum(w_true)\n",
    "    return w_true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f866c49",
   "metadata": {},
   "source": [
    "Make a radius distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567aa762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# radius vector\n",
    "r = torch.linspace(500., 1000., 300)\n",
    "\n",
    "# Make a crazy radius distribution with Gaussian and random\n",
    "w_true = crazy_distribution(r, [(4, 580, 10), (6, 630, 20), (10, 700, 20), \n",
    "                                (12, 750, 20), (8, 850, 15), (5, 930, 15)],\n",
    "                            noise_level=10, fade_start=10, fade_end=40)\n",
    "\n",
    "# upsample weights to a higher resolution for later use\n",
    "high_reso = 400\n",
    "r_high = torch.linspace(r[0], r[-1], high_reso)\n",
    "w_true_high = torch.tensor(interpolate.interp1d(r, w_true)(r_high))\n",
    "w_true_high /= torch.sum(w_true_high)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f97f25",
   "metadata": {},
   "source": [
    "### Ground truth of intensity\n",
    "\n",
    "Now, based on the above radius distribution, we compute the ground truth of intensity. \n",
    "\n",
    "Note that the parameter `scale` in [SASView/SASModels](http://www.sasview.org/docs/user/models/sphere.html) is not the $\\xi$ in `ffsas`. For the particular unit system of [SASView/SASModels](http://www.sasview.org/docs/user/models/sphere.html), the relation between `scale` and $\\xi$ is\n",
    "\n",
    "$$\\xi=10^{-4}\\times\\dfrac{\\mathrm{scale}}{V_\\text{ave}},$$\n",
    "\n",
    "where $10^{-4}$ comes from the unit system and $V_\\text{ave}$ is the average volume. The `background` in [SASView/SASModels](http://www.sasview.org/docs/user/models/sphere.html) has the same definition as $b$ in `ffsas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca957e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground truth of scale and background\n",
    "scale_true = 2.5\n",
    "b_true = .14\n",
    "\n",
    "# q vector\n",
    "q = torch.linspace(.001, 1, 2000)\n",
    "\n",
    "# (SLD - SLD_solvent) ^ 2\n",
    "drho = 25.\n",
    "\n",
    "# comupute the Green's function and volume\n",
    "G = Sphere.compute_G_mini_batch([q], {'r': r}, {'drho': drho})\n",
    "\n",
    "# compute the ground truth of xi\n",
    "V = Sphere.compute_V({'r': r})\n",
    "V_ave = torch.dot(V, w_true)\n",
    "xi_true = 1e-4 * scale_true / V_ave\n",
    "\n",
    "# define the G-based SAS system\n",
    "g_sys = SASGreensSystem(G, Sphere.get_par_keys_G(), log_screen=True)\n",
    "\n",
    "# finally compute the ground truth of intensity\n",
    "I_true = g_sys.compute_intensity({'r': w_true}, xi_true, b_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd93f61a",
   "metadata": {},
   "source": [
    "Plot the ground truths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48703df",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=200, ncols=2, figsize=(15, 4))\n",
    "ax[0].plot(r, w_true)\n",
    "ax[0].set_xlabel(r'Radius, $r$ ($\\AA$)')\n",
    "ax[0].set_ylabel(r'Weights, $w$')\n",
    "ax[1].plot(q, I_true)\n",
    "ax[1].set_xscale('log')\n",
    "ax[1].set_yscale('log')\n",
    "ax[1].set_xlabel(r'Scattering vector, $q$ ($\\AA^{-1}$)')\n",
    "ax[1].set_ylabel(r'Intensity, $I$ ($\\mathrm{cm}^{-1}$)')\n",
    "plt.savefig(f'{output_dir}/truth.png', bbox_inches='tight', facecolor='w')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fc299d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbedaa4b",
   "metadata": {},
   "source": [
    "#  Inversion\n",
    "\n",
    "Now we solve the inverse problem at different radius resolutions. It is expected that we \"exactly\" reproduce the ground truth with the resolution it was created, or 300 (`r = torch.linspace(500., 1000., 300)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab56f72f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# solve at five resolutions\n",
    "resolutions = [50, 100, 200, 300, 400]\n",
    "results = []\n",
    "\n",
    "# to avoid some drifting at low resolution 50, we do not use 1.0\n",
    "nu_sigma = 0.8  \n",
    "\n",
    "# loop over resolutions\n",
    "for reso in resolutions:\n",
    "    # resampled r vector at given resolution\n",
    "    r_reso = torch.linspace(r[0], r[-1], reso)\n",
    "    \n",
    "    # recompute G\n",
    "    G_reso = Sphere.compute_G_mini_batch([q], {'r': r_reso}, {'drho': drho}, log_screen=False)\n",
    "    \n",
    "    # define the system\n",
    "    g_sys_reso = SASGreensSystem(G_reso, par_keys=Sphere.get_par_keys_G(), \n",
    "                                 log_file=output_dir / f'resolution{reso}.log', \n",
    "                                 log_screen=False)  # log only to files, not displayed on screen\n",
    "    \n",
    "    # solve the inverse problem using \"true\" intensity\n",
    "    # NOTE: we do not have sigma or data uncertainty, so we use mu as sigma\n",
    "    result_dict = g_sys_reso.solve_inverse(I_true, I_true, nu_sigma=nu_sigma,\n",
    "                                           auto_scaling=True, maxiter=1000, verbose=2)\n",
    "    \n",
    "    # get weights from result dict\n",
    "    w_reso = result_dict['w_dict']['r']\n",
    "    sens_w_reso = result_dict['sens_w_dict']['r']\n",
    "    \n",
    "    # compute scale \n",
    "    scale = result_dict['xi'] * V_ave / 1e-4\n",
    "\n",
    "    # upsample w to high resolution so we can plot them together\n",
    "    w_high = torch.tensor(interpolate.interp1d(r_reso, w_reso)(r_high))\n",
    "    w_high /= torch.sum(w_high)\n",
    "    sens_w_high = torch.tensor(interpolate.interp1d(r_reso, sens_w_reso)(r_high))\n",
    "    sens_w_high /= torch.sum(sens_w_high)\n",
    "    results.append((reso, w_reso, w_high, sens_w_high, scale, result_dict['xi'], result_dict['b'], \n",
    "                    result_dict['I'], result_dict['wct']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205b6922",
   "metadata": {},
   "source": [
    "Finally, plot the results at the different resolutions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a941bf4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# scaling factor to plot 1/sensitivity as uncertainty \n",
    "scaling_factor_sensitivity = 3e-6\n",
    "\n",
    "fig, ax = plt.subplots(nrows=len(results), ncols=2, dpi=200, figsize=(16, len(results) * 3))\n",
    "plt.subplots_adjust(hspace=.3)\n",
    "if len(results) == 1:\n",
    "    ax = [ax]\n",
    "\n",
    "for i, (reso, w_reso, w_high, sens_w_high, scale, xi, b, I, wct) in enumerate(results):\n",
    "    #######################\n",
    "    # radius distribution #\n",
    "    #######################\n",
    "    # truth\n",
    "    ax[i][0].scatter(r_high, w_true_high, lw=0, c=colors[0], s=30, label=r'Truth')\n",
    "    # inverted\n",
    "    ax[i][0].plot(r_high, w_high, c=colors[1], label=r'MLE')\n",
    "    dw_norm = torch.norm(w_true_high - w_high) ** 2 / len(w_high)\n",
    "    # 1/sensitivity\n",
    "    sens_scaled = scaling_factor_sensitivity / sens_w_high\n",
    "    ax[i][0].fill_between(r_high, w_high - abs(sens_scaled), w_high + abs(sens_scaled), \n",
    "                          alpha=.3, color='gray', zorder=-100, label=r'Sens${}^{-1}$')\n",
    "    ax[i][0].set_title(r'Res.=%d: scale=%.2f, $b$=%.3f, $|\\Delta w|^2$=%.2E' % (reso, scale, b, dw_norm))\n",
    "    ax[i][0].set_ylim(-0.001, 0.01)\n",
    "    ax[i][0].set_ylabel(r'Weights, $w$')\n",
    "    if i != len(results) - 1:\n",
    "        ax[i][0].set_xticklabels([])\n",
    "    else:\n",
    "        ax[i][0].set_xlabel(r'Radius, $r$ ($\\AA$)')\n",
    "    \n",
    "    #####################\n",
    "    # intensity fitting #\n",
    "    #####################\n",
    "    chi2 = torch.norm((I_true - I) / I_true ** nu_sigma) ** 2 / len(I_true)\n",
    "    # truth\n",
    "    ax[i][1].scatter(q, I_true, lw=0, c=colors[2], s=30, label=r'Truth')\n",
    "    # fitted\n",
    "    ax[i][1].plot(q, I, c=colors[3], label=r'Fitted')\n",
    "    ax[i][1].set_title(r'Res.=%d: $\\chi^2$=%.2E, wct=%.1f sec' % (reso, chi2, wct))\n",
    "    ax[i][1].set_xscale('log')\n",
    "    ax[i][1].set_yscale('log')\n",
    "    ax[i][1].set_ylabel(r'Intensity, $I$ ($\\mathrm{cm}^{-1}$)')\n",
    "    if i != len(results) - 1:\n",
    "        ax[i][1].set_xticklabels([])\n",
    "    else:\n",
    "        ax[i][1].set_xlabel(r'Scattering vector, $q$ ($\\AA^{-1}$)')\n",
    "    \n",
    "    # add some text\n",
    "    if reso == 300:\n",
    "        ax[i][0].text(.97, .92, 'Exact', transform=ax[i][0].transAxes, \n",
    "                     ha='right', va='top', fontsize=18, color='k')\n",
    "        ax[i][1].text(.97, .92, 'Exact', transform=ax[i][1].transAxes, \n",
    "                     ha='right', va='top', fontsize=18, color='k')\n",
    "\n",
    "order = [1, 0, 2]\n",
    "handles, labels = ax[0][0].get_legend_handles_labels()\n",
    "ax[0][0].legend([handles[idx] for idx in order], [labels[idx] for idx in order])\n",
    "handles, labels = ax[0][1].get_legend_handles_labels()\n",
    "order = [1, 0]\n",
    "ax[0][1].legend([handles[idx] for idx in order], [labels[idx] for idx in order])\n",
    "plt.savefig(output_dir / 'results.png', bbox_inches='tight', facecolor='w')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51a1df8",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
