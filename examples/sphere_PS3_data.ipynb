{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: sphere with PS3 dataset\n",
    "\n",
    "This notebook shows how to use `ffsas` to invert for the radius distribution of a `Sphere` model with a real dataset called \"PS3\". It uses the [SASView/SASModels](http://www.sasview.org/docs/user/models/sphere.html) unit system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avoid omp error on Mac\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "# plotting setup\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 14})\n",
    "matplotlib.rcParams.update({'legend.fontsize': 14})\n",
    "matplotlib.rcParams.update({'axes.titlesize': 14})\n",
    "matplotlib.rcParams.update({'lines.linewidth': 1})\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"text.latex.preamble\":  r'\\usepackage{bm,upgreek}',\n",
    "    \"font.family\": \"sans-serif\",\n",
    "    \"font.serif\": [\"Times\"]})\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "# create output dir\n",
    "from pathlib import Path\n",
    "paper_fig_dir = Path('./output/paper_fig')\n",
    "Path(paper_fig_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment this line to install ffsas\n",
    "# !pip install ffsas\n",
    "\n",
    "# ffsas\n",
    "import torch\n",
    "import ffsas\n",
    "from ffsas.models import Sphere\n",
    "from ffsas.system import SASGreensSystem\n",
    "\n",
    "# math tools\n",
    "from scipy import interpolate\n",
    "\n",
    "# numpy for reading data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data\n",
    "\n",
    "Data are stored in the text file `PS3_data/observation.txt`, with the three columns being $q$, mean and standard deviation of the observed intensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "fname = f'PS3_data/observation.txt'\n",
    "data = np.loadtxt(fname)\n",
    "\n",
    "# q vector\n",
    "q = torch.tensor(data[:, 0], dtype=ffsas.torch_dtype)\n",
    "\n",
    "# intensity mean\n",
    "mu = torch.tensor(data[:, 1], dtype=ffsas.torch_dtype)\n",
    "\n",
    "# intensity stddev\n",
    "sigma = torch.tensor(data[:, 2], dtype=ffsas.torch_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inversion\n",
    "\n",
    "Just a few lines to do inversion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify radii\n",
    "r = torch.linspace(400, 800, 1000)\n",
    "\n",
    "# compute the Green's tensor\n",
    "truncate = 285  # truncate noise part at high-q\n",
    "G = Sphere.compute_G_mini_batch([q[:truncate]], {'r': r}, {'drho': 1.})\n",
    "\n",
    "# build G-system\n",
    "g_sys = SASGreensSystem(G, Sphere.get_par_keys_G())\n",
    "\n",
    "# inversion\n",
    "# do 1000 iterations and save every 100 iterations\n",
    "results = g_sys.solve_inverse(mu[:truncate], sigma[:truncate], maxiter=1000, save_iter=100, \n",
    "                              trust_options={'xtol': 0, 'gtol':0}, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot results\n",
    "\n",
    "First plot `ffsas` results at different iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# volume\n",
    "v = r ** 3\n",
    "\n",
    "# colormap\n",
    "cmap = matplotlib.cm.get_cmap('turbo_r')\n",
    "\n",
    "# steps to plot (every 100 iters)\n",
    "n_results = len(results['saved_res'])\n",
    "plot_steps = range(n_results)\n",
    "\n",
    "# plot\n",
    "fig=plt.figure(dpi=200, figsize=(7/1.4, 3.5/1.4))\n",
    "for j, step in enumerate(plot_steps):\n",
    "    w = results['saved_res'][step]['w_dict']['r']\n",
    "    w_hat = w * v / (w * v).sum() * 100  # x100 to percent\n",
    "    plt.plot(r, w_hat, zorder=-j, c=cmap(step / (n_results - 1)),\n",
    "             label=r'$w(r)$, iters=%d, wct=%.1f sec' % \n",
    "             (results['saved_res'][step]['nit'], \n",
    "              results['saved_res'][step]['wct']))\n",
    "    \n",
    "plt.xlim(r.min(), r.max())\n",
    "plt.ylabel(r'Volume weight, $\\hat{w}_v$ (\\%)')\n",
    "plt.xlabel(r'Radius, $r$ (\\AA)')\n",
    "plt.title(r'(a) Convergence of $\\hat{w}_v(r)$ in FFSAS')\n",
    "\n",
    "\n",
    "# Gaussian approximations of populations\n",
    "r_ranges=[[420, 500],\n",
    "          [500, 600],\n",
    "          [600, 675],\n",
    "          [675, 800]]\n",
    "    \n",
    "for i, (r_min, r_max) in enumerate(r_ranges):\n",
    "    # find peak\n",
    "    i_min = torch.argmin(torch.abs(r - r_min))\n",
    "    i_max = torch.argmin(torch.abs(r - r_max))\n",
    "    max_loc = torch.argmax(w_hat[i_min:i_max])\n",
    "    r_top = r[i_min + max_loc]\n",
    "    \n",
    "    # find stddev\n",
    "    area_all = torch.sum(w_hat[i_min:i_max])\n",
    "    for stddev in range(1, 50):\n",
    "        area = torch.sum(w_hat[i_min + max_loc - stddev:i_min + max_loc + stddev])\n",
    "        if area >= area_all * .68:\n",
    "            break\n",
    "\n",
    "    # texts\n",
    "    if r_max == 800:\n",
    "        plt.text(r_top - 1, w_hat[i_min + max_loc] - 2.2, \n",
    "                 r'$\\mathcal{N}(%d,%d^2)$' % (round(r_top.item()), \n",
    "                                              round(stddev / len(r) * (r.max() - r.min()).item())), \n",
    "                 ha='left', va='center', fontsize=13, rotation=45)\n",
    "    else:\n",
    "        plt.text(r_top - 20, max(w_hat[i_min + max_loc] + 1., .7), \n",
    "                 r'$\\mathcal{N}(%d,%d^2)$' % (round(r_top.item()), \n",
    "                                              round(stddev / len(r) * (r.max() - r.min()).item())), \n",
    "                 ha='left', va='bottom', fontsize=13, rotation=45)\n",
    "plt.ylim(None, 17)\n",
    "\n",
    "# legend                 \n",
    "norm = matplotlib.colors.Normalize(vmin=0, vmax=1000)\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cbaxes = fig.add_axes([0.18, 0.73, 0.45, .025]) \n",
    "cb = plt.colorbar(sm, ticks=np.arange(100,1001,100), \n",
    "                  boundaries=np.arange(50,1101,100),\n",
    "                  cax=cbaxes, orientation='horizontal')\n",
    "cb.ax.tick_params(labelsize=13) \n",
    "cb.ax.set_title('Num. iterations', fontsize=13)\n",
    "cb.ax.tick_params(axis='x', labelrotation = 45)\n",
    "\n",
    "# save for paper\n",
    "plt.savefig(paper_fig_dir / 'PS3a.pdf', bbox_inches='tight', facecolor='w', padding_inches=.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compare `ffsas`, `McSAS` and `SasView` results. Because the `McSAS` and `SasView` are very smooth, we compare them to an early `ffsas` result (at 30 iterations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inversion at 30 iters\n",
    "results_early = g_sys.solve_inverse(mu[:truncate], sigma[:truncate], maxiter=30, \n",
    "                                    trust_options={'xtol': 0, 'gtol':0}, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(dpi=200, figsize=(7/1.4, 3.5/1.4))\n",
    "\n",
    "#### FFSAS ####\n",
    "w_ffsas = results_early['w_dict']['r']\n",
    "w_hat_ffsas = w_ffsas * v / (w_ffsas * v).sum() * 100\n",
    "plt.plot(r, w_hat_ffsas, zorder=1000000, lw=1.5, ls='-',\n",
    "         label=r'FFSAS (%d iters),' % (results_early['opt_res']['nit'],))\n",
    "plt.plot(r, w_hat_ffsas, zorder=-1000000, lw=1.5, ls='-', c='w',\n",
    "         label=r'wt=%.1f sec' % (results_early['wct'],))\n",
    "\n",
    "#### MCSAS ####\n",
    "# read\n",
    "data = np.loadtxt('PS3_data/mcsas_w(r).dat', skiprows=1)\n",
    "vol_frac_low = data[:, 2]\n",
    "\n",
    "# convert to the same resolution\n",
    "x = np.linspace(400, 800, len(vol_frac_low))\n",
    "vol_frac_high = interpolate.interp1d(x, vol_frac_low)(r)\n",
    "\n",
    "# denoise a little bit to make it look better\n",
    "nn = 10\n",
    "vol_frac_denoise = np.convolve(vol_frac_high, np.ones(nn), 'same') / nn\n",
    "vol_frac_denoise = vol_frac_denoise / vol_frac_denoise.sum() * 100\n",
    "plt.plot(r, vol_frac_denoise, zorder=1, lw=1.5, ls='--',label=r'McSAS ($\\chi^2$-limit),')\n",
    "plt.plot(r, vol_frac_denoise, zorder=-1000000, lw=1.5, ls='--', c='w', label=r'wt=80.5 sec')\n",
    "\n",
    "\n",
    "#### SASView ####\n",
    "# read\n",
    "r_mean, PD, scale_sasview, b_sasview = np.loadtxt('PS3_data/sasview_gaussian.txt', skiprows=1)\n",
    "sigm = r_mean * PD\n",
    "\n",
    "# compute w and w_hat\n",
    "w_sasview = torch.exp(-.5*((r - r_mean) / sigm) ** 2)\n",
    "w_sasview = w_sasview / w_sasview.sum()\n",
    "w_hat_sasview = w_sasview * v / torch.sum(w_sasview * v) * 100\n",
    "\n",
    "# plot\n",
    "plt.plot(r, w_hat_sasview, zorder=100, lw=1.5, ls='-.', label='SasView (Gaussian),')\n",
    "plt.plot(r, w_hat_sasview, zorder=-100000, lw=1.5, c='w', ls='-.', label='wt=1.0 sec')\n",
    "\n",
    "\n",
    "# figure setting\n",
    "plt.xlim(400, 800)\n",
    "plt.ylabel(r'Volume weight, $\\hat{w}$ (\\%)')\n",
    "plt.xlabel(r'Radius, $r$ (\\AA)')\n",
    "plt.legend(loc=[0.01, .27], prop={'size': 12}, labelspacing=.3)\n",
    "plt.title(r\"(b) $\\hat{w}_v(r)$'s from different methods\")\n",
    "\n",
    "# save for paper\n",
    "plt.savefig(paper_fig_dir / 'PS3b.pdf', bbox_inches='tight', facecolor='w', padding_inches=.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we compare the intensity fit. First, we compute the predicted intensities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full Green's tensor across q range\n",
    "G_full = Sphere.compute_G_mini_batch([q], {'r': r}, {'drho': 1.})\n",
    "g_sys_full = SASGreensSystem(G_full, Sphere.get_par_keys_G())\n",
    "\n",
    "# FFSAS\n",
    "I_ffsas = g_sys_full.compute_intensity(w_dict=results_early['w_dict'], \n",
    "                                       xi=results['xi'], b=results['b'])\n",
    "\n",
    "# # McSAS\n",
    "xi_mcsas, b_mcsas = np.loadtxt('PS3_data/mcsas_xi_b.txt', skiprows=1)\n",
    "w_mcsas = vol_frac_high / v / (vol_frac_high / v).sum()\n",
    "I_mcsas = g_sys_full.compute_intensity(w_dict={'r': w_mcsas}, xi=xi_mcsas, b=b_mcsas)\n",
    "\n",
    "# SasView\n",
    "xi_sasview = 1e-4 * scale_sasview / (w_sasview * (4 / 3 * np.pi * r ** 3)).sum() \n",
    "I_sasview = g_sys_full.compute_intensity(w_dict={'r': w_sasview}, \n",
    "                                         xi=xi_sasview, b=b_sasview)\n",
    "\n",
    "# Monodisperse at 710 A\n",
    "w_delta = results['w_dict']['r'].clone()\n",
    "w_delta[:] = 0\n",
    "w_delta[775]=1  # location of 710 A is 775\n",
    "# xi and b are found by SasView\n",
    "scale_delta, b_delta = np.loadtxt('PS3_data/sasview_monodisperse710.txt', skiprows=1)\n",
    "xi_delta = 1e-4 * scale_delta / (4 / 3 * np.pi * 710 ** 3)\n",
    "I_delta = g_sys_full.compute_intensity(w_dict={'r': w_delta}, xi=xi_delta, b=b_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams.update({'font.size': 12})\n",
    "matplotlib.rcParams.update({'legend.fontsize': 12})\n",
    "matplotlib.rcParams.update({'axes.titlesize': 12})\n",
    "\n",
    "\n",
    "fig=plt.figure(dpi=200, figsize=(7/1., 2.52/1.))\n",
    "\n",
    "# data\n",
    "plt.errorbar(q, mu, yerr=sigma, c='pink', ecolor='skyblue', lw=1, fmt='o',\n",
    "             markersize=3, label=r'Observation', zorder=-100)\n",
    "\n",
    "# FFSAS\n",
    "I = I_ffsas\n",
    "eps_norm = np.linalg.norm((mu[:truncate] - I[:truncate]) / sigma[:truncate]) / truncate\n",
    "plt.plot(q, I, ls='-', lw=2, zorder=0,\n",
    "         label=r'FFSAS (30 iters),')\n",
    "plt.plot(q, I, ls='-', lw=2, zorder=-10000000000, c='w',\n",
    "         label=r'$||\\bm{\\upepsilon}||$=%.2f' % (eps_norm))    \n",
    "\n",
    "    \n",
    "# McSAS\n",
    "I = I_mcsas\n",
    "eps_norm = np.linalg.norm((mu[:truncate] - I[:truncate]) / sigma[:truncate]) / truncate\n",
    "plt.plot(q, I, ls='--', lw=2,\n",
    "         label=r'McSAS ($\\chi^2$-limit),')\n",
    "plt.plot(q, I, ls='--', lw=2, zorder=-10000000000, c='w',\n",
    "         label=r'$||\\bm{\\upepsilon}||$=%.2f' % (eps_norm))\n",
    "\n",
    "# SASView\n",
    "I = I_sasview\n",
    "eps_norm = np.linalg.norm((mu[:truncate] - I[:truncate]) / sigma[:truncate]) / truncate\n",
    "plt.plot(q, I, ls='-.', lw=2,\n",
    "         label=r'SasView (Gaussian),' )\n",
    "plt.plot(q, I, ls='-.', lw=2, zorder=-10000000000, c='w',\n",
    "         label=r'$||\\bm{\\upepsilon}||$=%.2f' % (eps_norm))\n",
    "\n",
    "# monodisperse\n",
    "I = I_delta\n",
    "eps_norm = np.linalg.norm((mu[:truncate] - I[:truncate]) / sigma[:truncate]) / truncate\n",
    "plt.plot(q, I, ls='-', lw=1, zorder=-10,\n",
    "         label=r'Monodispersity at' )\n",
    "plt.plot(q, I, ls='-', lw=1, zorder=-10000000000, c='w',\n",
    "         label=r'$r=710$ \\AA, $||\\bm{\\upepsilon}||$=%.2f' % (eps_norm))\n",
    "\n",
    "plt.axvline(q[truncate], lw=1.5, c='k', ls=':')\n",
    "plt.text(q[truncate] / 1.05, 10**4.3, 'Truncation', color='k',\n",
    "         rotation=90, ha='right', va='top', fontsize=11)\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Scattering vector, $q$ (\\AA$^{-1}$)')\n",
    "plt.ylabel('Intensity, $I$ ($\\mathrm{cm}^{-1}$)')\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "handles.insert(0, handles.pop())\n",
    "labels.insert(0, labels.pop())\n",
    "plt.legend(handles, labels, loc=[1.02, 0.0],\n",
    "           prop={'size': 10})\n",
    "plt.ylim((10**(-3), 10 ** 4.5))\n",
    "plt.xlim(q[0] / 1.1, 1.e-1)\n",
    "plt.title(r\"(c) Intensity data and $I(q)$'s from different methods\")\n",
    "\n",
    "# save for paper\n",
    "plt.savefig(paper_fig_dir / 'PS3c.pdf', bbox_inches='tight', facecolor='w', padding_inches=.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
