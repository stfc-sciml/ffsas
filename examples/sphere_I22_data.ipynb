{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: sphere with I22 dataset\n",
    "\n",
    "This notebook shows how to use `ffsas` to invert for the radius distribution of a `Sphere` model with a real dataset called \"I22\". It uses the [SASView/SASModels](http://www.sasview.org/docs/user/models/sphere.html) unit system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avoid omp error on Mac\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "# plotting setup\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 14})\n",
    "matplotlib.rcParams.update({'legend.fontsize': 14})\n",
    "matplotlib.rcParams.update({'axes.titlesize': 14})\n",
    "matplotlib.rcParams.update({'lines.linewidth': 1})\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"text.latex.preamble\":  r'\\usepackage{bm,upgreek}',\n",
    "    \"font.family\": \"sans-serif\",\n",
    "    \"font.serif\": [\"Times\"]})\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "# create output dir\n",
    "from pathlib import Path\n",
    "paper_fig_dir = Path('./output/paper_fig')\n",
    "Path(paper_fig_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment this line to install ffsas\n",
    "# !pip install ffsas\n",
    "\n",
    "# ffsas\n",
    "import torch\n",
    "import ffsas\n",
    "from ffsas.models import Sphere\n",
    "from ffsas.system import SASGreensSystem\n",
    "\n",
    "# math tools\n",
    "from scipy import interpolate\n",
    "\n",
    "# numpy for reading data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data\n",
    "\n",
    "Data are stored in the text file `I22_data/observation.txt`, with the three columns being $q$, mean and standard deviation of the observed intensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "fname = f'I22_data/observation.txt'\n",
    "data = np.loadtxt(fname)\n",
    "\n",
    "# q vector\n",
    "q = torch.tensor(data[:, 0], dtype=ffsas.torch_dtype)\n",
    "\n",
    "# intensity mean\n",
    "mu = torch.tensor(data[:, 1], dtype=ffsas.torch_dtype)\n",
    "\n",
    "# intensity stddev\n",
    "sigma = torch.tensor(data[:, 2], dtype=ffsas.torch_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inversion\n",
    "\n",
    "Just a few lines to do inversion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify radii\n",
    "r = torch.linspace(400, 1200, 1000)\n",
    "\n",
    "# compute the Green's tensor\n",
    "G = Sphere.compute_G_mini_batch([q], {'r': r}, {'drho': 1.})\n",
    "\n",
    "# build G-system\n",
    "g_sys = SASGreensSystem(G, Sphere.get_par_keys_G())\n",
    "\n",
    "# inversion\n",
    "# do 500 iterations and save every 100 iterations\n",
    "results = g_sys.solve_inverse(mu, sigma, maxiter=500, save_iter=100, \n",
    "                              trust_options={'xtol': 0, 'gtol':0}, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot results\n",
    "\n",
    "First plot `ffsas` results at different iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# volume\n",
    "v = r ** 3\n",
    "\n",
    "# colormap\n",
    "cmap = matplotlib.cm.get_cmap('turbo_r')\n",
    "\n",
    "# steps to plot (every 100 iters)\n",
    "n_results = len(results['saved_res'])\n",
    "plot_steps = range(n_results)\n",
    "\n",
    "# plot\n",
    "fig=plt.figure(dpi=200, figsize=(7/1.4, 3.5/1.4))\n",
    "for j, step in enumerate(plot_steps):\n",
    "    w = results['saved_res'][step]['w_dict']['r']\n",
    "    w_hat = w * v / (w * v).sum() * 100  # x100 to percent\n",
    "    plt.plot(r, w_hat, zorder=-j, c=cmap(step / (n_results - 1)),\n",
    "             label=r'$w(r)$, iters=%d, wct=%.1f sec' % \n",
    "             (results['saved_res'][step]['nit'], \n",
    "              results['saved_res'][step]['wct']))\n",
    "    \n",
    "plt.xlim(r.min(), r.max())\n",
    "plt.ylabel(r'Volume weight, $\\hat{w}_v$ (\\%)')\n",
    "plt.xlabel(r'Radius, $r$ (\\AA)')\n",
    "plt.title(r'Convergence of $\\hat{w}_v(r)$ in FFSAS')\n",
    "\n",
    "\n",
    "# Gaussian approximations of populations\n",
    "r_ranges=[[420, 800],\n",
    "          [800, 1180]]\n",
    "\n",
    "area_all_ffsas = []\n",
    "for i, (r_min, r_max) in enumerate(r_ranges):\n",
    "    # find peak\n",
    "    i_min = torch.argmin(torch.abs(r - r_min))\n",
    "    i_max = torch.argmin(torch.abs(r - r_max))\n",
    "    max_loc = torch.argmax(w_hat[i_min:i_max])\n",
    "    r_top = r[i_min + max_loc]\n",
    "    \n",
    "    # find stddev\n",
    "    area_all = torch.sum(w_hat[i_min:i_max])\n",
    "    area_all_ffsas.append(area_all)\n",
    "    for stddev in range(1, 50):\n",
    "        area = torch.sum(w_hat[i_min + max_loc - stddev:i_min + max_loc + stddev])\n",
    "        if area >= area_all * .68:\n",
    "            break\n",
    "\n",
    "    # texts\n",
    "    if r_max == 800:\n",
    "        plt.text(r_top - 1, w_hat[i_min + max_loc] - 2.2, \n",
    "                 r'$\\mathcal{N}(%d,%d^2)$' % (round(r_top.item()), \n",
    "                                              round(stddev / len(r) * (r.max() - r.min()).item())), \n",
    "                 ha='left', va='center', fontsize=12, rotation=45)\n",
    "    else:\n",
    "        plt.text(r_top - 20, max(w_hat[i_min + max_loc] + 1., .7), \n",
    "                 r'$\\mathcal{N}(%d,%d^2)$' % (round(r_top.item()), \n",
    "                                              round(stddev / len(r) * (r.max() - r.min()).item())), \n",
    "                 ha='left', va='bottom', fontsize=12, rotation=45)\n",
    "plt.ylim(None, 40)\n",
    "\n",
    "# legend                 \n",
    "norm = matplotlib.colors.Normalize(vmin=0, vmax=1000)\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cbaxes = fig.add_axes([0.18, 0.73, 0.45, .025]) \n",
    "cb = plt.colorbar(sm, ticks=np.arange(100,1001,100), \n",
    "                  boundaries=np.arange(50,1101,100),\n",
    "                  cax=cbaxes, orientation='horizontal')\n",
    "cb.ax.tick_params(labelsize=12) \n",
    "cb.ax.set_title('Num. iterations', fontsize=12)\n",
    "cb.ax.tick_params(axis='x', labelrotation = 45)\n",
    "plt.show()\n",
    "\n",
    "# volume ratio of the two populations\n",
    "v1 = area_all_ffsas[0] / (area_all_ffsas[0] + area_all_ffsas[1])\n",
    "print(f'FFSAS v1/v2 = {v1:.2f}:{1 - v1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compare `ffsas`, `McSAS` and `SasView` results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### MCSAS ####\n",
    "# read\n",
    "data = np.loadtxt('I22_data/mcsas_w(r).dat', skiprows=1)\n",
    "vol_frac_low = data[:, 2]\n",
    "\n",
    "# convert to the same resolution\n",
    "x = np.linspace(400, 1200, len(vol_frac_low))\n",
    "vol_frac_high = torch.from_numpy(interpolate.interp1d(x, vol_frac_low)(r))\n",
    "\n",
    "# Gaussian approximation\n",
    "area_all_mcsas = []\n",
    "for i, (r_min, r_max) in enumerate(r_ranges):\n",
    "    # find peak\n",
    "    i_min = torch.argmin(torch.abs(r - r_min))\n",
    "    i_max = torch.argmin(torch.abs(r - r_max))\n",
    "    max_loc = torch.argmax(vol_frac_high[i_min:i_max])\n",
    "    r_top = r[i_min + max_loc]\n",
    "    \n",
    "    # find stddev\n",
    "    area_all = torch.sum(vol_frac_high[i_min:i_max])\n",
    "    area_all_mcsas.append(area_all)\n",
    "    for stddev in range(1, 50):\n",
    "        area = torch.sum(vol_frac_high[i_min + max_loc - stddev:i_min + max_loc + stddev])\n",
    "        if area >= area_all * .68:\n",
    "            break\n",
    "    print(f'McSAS N({r_top}, {round(stddev / len(r) * (r.max() - r.min()).item())}^2)')        \n",
    "    \n",
    "# volume ratio of the two populations\n",
    "v1 = area_all_mcsas[0] / (area_all_mcsas[0] + area_all_mcsas[1])\n",
    "print(f'McSAS v1/v2 = {v1:.2f}:{1 - v1:.2f}')\n",
    "\n",
    "#### SASView ####\n",
    "# read\n",
    "r_mean1, PD1, scale1, r_mean2, PD2, scale2, scale, b = np.loadtxt('I22_data/sasview_gaussian.txt', skiprows=1)\n",
    "sigm1 = r_mean1 * PD1\n",
    "sigm2 = r_mean2 * PD2\n",
    "print(f'SasView N({r_mean1}, {sigm1}^2)')\n",
    "print(f'SasView N({r_mean2}, {sigm2}^2)')\n",
    "v1 = scale1 / (scale1 + scale2)\n",
    "print(f'SasView v1/v2 = {v1:.2f}:{1 - v1:.2f}')\n",
    "\n",
    "# weights\n",
    "g1 = torch.exp(-.5 * ((r - r_mean1) / sigm1) ** 2)\n",
    "g2 = torch.exp(-.5 * ((r - r_mean2) / sigm2) ** 2)\n",
    "w_sasview = scale1 * g1 / r_mean1**3 + scale2 * g2 / r_mean2**3\n",
    "w_sasview /= w_sasview.sum()\n",
    "scale *= scale1 + scale2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we compare the intensity fit. First, we compute the predicted intensities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_sys_full = g_sys\n",
    "\n",
    "# FFSAS\n",
    "I_ffsas = g_sys_full.compute_intensity(w_dict=results['w_dict'], \n",
    "                                       xi=results['xi'], b=results['b'])\n",
    "\n",
    "# McSAS\n",
    "xi_mcsas, b_mcsas = np.loadtxt('I22_data/mcsas_xi_b.txt', skiprows=1)\n",
    "w_mcsas = vol_frac_high / v / (vol_frac_high / v).sum()\n",
    "I_mcsas = g_sys_full.compute_intensity(w_dict={'r': w_mcsas}, xi=xi_mcsas, b=b_mcsas)\n",
    "\n",
    "# # SasView\n",
    "xi_sasview = 1e-4 * scale / (w_sasview * (4 / 3 * np.pi * r ** 3)).sum() \n",
    "I_sasview = g_sys_full.compute_intensity(w_dict={'r': w_sasview}, \n",
    "                                         xi=xi_sasview, b=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams.update({'font.size': 12.5})\n",
    "matplotlib.rcParams.update({'legend.fontsize': 12.5})\n",
    "matplotlib.rcParams.update({'axes.titlesize': 12.5})\n",
    "\n",
    "\n",
    "fig=plt.figure(dpi=200, figsize=(7.5/1.4, 3.8/1.4))\n",
    "\n",
    "# data\n",
    "plt.errorbar(q, mu, yerr=sigma, c='pink', ecolor='skyblue', lw=1, fmt='o',\n",
    "             markersize=3, label=r'Observation', zorder=-100)\n",
    "\n",
    "# FFSAS\n",
    "I = I_ffsas\n",
    "eps_norm = np.linalg.norm((mu - I) / sigma) / len(mu)\n",
    "plt.plot(q, I, ls='-', lw=1.5, zorder=100,\n",
    "         label=r'FFSAS (500 iters), wt=18 s, $||\\bm{\\upepsilon}||$=%.2f,' % (eps_norm))\n",
    "plt.plot(q, I, ls='-', lw=1.5, zorder=-10000000, color='w',\n",
    "         label=r'$\\hat{w}(r)=58\\%\\mathcal{N}(628, 2^2)+42\\%\\mathcal{N}(1059, 2^2)$') \n",
    "\n",
    "    \n",
    "# # McSAS\n",
    "I = I_mcsas\n",
    "eps_norm = np.linalg.norm((mu - I) / sigma) / len(mu)\n",
    "plt.plot(q, I, ls='--', lw=1.5, zorder=0,\n",
    "         label=r'McSAS ($\\chi^2$-limit), wt=1010 s, $||\\bm{\\upepsilon}||$=%.2f,' % (eps_norm))\n",
    "plt.plot(q, I, ls='--', lw=1.5, zorder=-10000000, color='w',\n",
    "         label=r'$\\hat{w}(r)=58\\%\\mathcal{N}(625, 6^2)+42\\%\\mathcal{N}(1063, 6^2)$')\n",
    "\n",
    "# SASView\n",
    "I = I_sasview\n",
    "eps_norm = np.linalg.norm((mu - I) / sigma) / len(mu)\n",
    "plt.plot(q, I, ls='-.', lw=1.5, zorder=0,\n",
    "         label=r'SasView (Gaussians), wt=2 s, $||\\bm{\\upepsilon}||$=%.2f,' % (eps_norm))\n",
    "plt.plot(q, I, ls='-.', lw=1.5, zorder=-10000000, color='w',\n",
    "         label=r'$\\hat{w}(r)=60\\%\\mathcal{N}(613, 0^2)+40\\%\\mathcal{N}(1058, 0^2)$')\n",
    "\n",
    "plt.xlim(q[0] / 1.1, q[-50])\n",
    "plt.ylim(.5e-4, 10**3.5)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Scattering vector, $q$ (\\AA$^{-1}$)')\n",
    "plt.ylabel('Intensity, $I$ ($\\mathrm{cm}^{-1}$)')\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "handles.insert(0, handles.pop())\n",
    "labels.insert(0, labels.pop())\n",
    "plt.legend(handles, labels, prop={'size': 11}, loc=[1.03,0.169], labelspacing=.5)\n",
    "\n",
    "# add some texts for paper\n",
    "plt.axvline(0.008, c='k', lw=1, ymin=.8)\n",
    "plt.axvline(0.04, c='k', lw=1, ymin=.8)\n",
    "plt.text(0.004, 1e3, r'low-$q$', va='top')\n",
    "plt.text(0.014, 1e3, r'mid-$q$', va='top')\n",
    "plt.text(0.08, 1e3, r'high-$q$', va='top', ha='center')\n",
    "\n",
    "# save for paper\n",
    "plt.savefig(paper_fig_dir / 'I22.pdf', bbox_inches='tight', facecolor='w', padding_inches=.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
